#### 那么工作中我们更倾向于使用什么方法呢？

首先来回顾一下我们在业务中的模型会遇到什么问题。

- 模型效果不好（ks，或者其他一些指标不佳）
分析：大概率时数据的问题
- 训练集效果好，跨时间测试效果不好
分析：跨时间测试数据进模型的特征的分布情况变动有关，可以通过PSI得到反应。可以考虑先在跨时间测试数据集建模选特征。
- 跨时间测试效果也好，上线之后效果不好
分析：线上线下变量的逻辑不一样
- 上线之后效果还好，几周之后分数分布开始下滑
分析：类似于跨时间测试效果不好，个别变量分布变动
- 一两个月内都比较稳定，突然分数分布骤降
分析：主要是外部原因，国家政策，或者运营渠道拉新（不好的客户）
- 没有明显问题，但模型每个月逐步失效
分析：这是一个永恒的话题，业内大部分公司都会遇到




然后我们来考虑一下业务所需要的变量是什么。

- 变量必须对模型有贡献，也就是说必须能对客群加以区分
- 逻辑回归要求变量之间线性无关
- 逻辑回归评分卡也希望变量呈现单调趋势 （有一部分也是业务原因，但从模型角度来看，单调变量未必一定比有转折的变量好）
- 客群在每个变量上的分布稳定，分布迁移无可避免，但不能波动太大  

为此我们从上述方法中找到最贴合当前使用场景的几种方法：
1）变量重要性

- IV值
- 卡方检验
- 模型筛选

分箱、WOE、IV
```
import numpy as np
import pandas as pd
from scipy import stats

def mono_bin(Y,X,n=20):
    r=0
    good = Y.sum()
    bad = Y.count()-good
    while np.abs(r)< 1:
        d1=pd.DataFrame({"X":X,"Y":Y,"Bucket":pd.qcut(X,n)})
        d2=d1.groupby('Bucket',as_index=True)
        r,p=stats.spearmanr(d2.mean().X,d2.mean().Y)
        n=n-1
    d3=pd.DataFrame(d2.X.min(),columns=['min'])
    d3['min']=d2.min().X
    d3['max']=d2.max().X
    d3['sum']=d2.sum().Y
    d3['total']=d2.count().Y
    d3['rate']=d2.mean().Y
    d3['woe']=np.log((d3['rate']/(1-d3['rate']))/(good/bad))
    d3['iv']=(d3['rate']/(1-d3['rate']) - (good/bad)) * np.log((d3['rate']/(1-d3['rate']))/(good/bad))
    d4=(d3.sort_index(by='min')).reset_index(drop=True)
    print("="*60)
    print(d4)
    return d4

```
或者集成模型输出特征重要性：
```
#lightGBM中的特征重要性
feature = pd.DataFrame(
            {'name' : model.booster_.feature_name(),
            'importance' : model.feature_importances_
          }).sort_values(by =  ['importance'],ascending = False)
```
2）共线性

- 相关系数 COR
- 方差膨胀系数 VIF  
df_train.corr()

3）单调性

bivar图
```
# 等频切分
df_train.loc[:,'fare_qcut'] = pd.qcut(df_train['Fare'], 10)
df_train.head()
df_train = df_train.sort_values('Fare')
alist = list(set(df_train['fare_qcut']))
badrate = {}
for x in alist:
    
    a = df_train[df_train.fare_qcut == x]
    
    bad = a[a.label == 1]['label'].count()
    good = a[a.label == 0]['label'].count()
    
    badrate[x] = bad/(bad+good)
f = zip(badrate.keys(),badrate.values())
f = sorted(f,key = lambda x : x[1],reverse = True )
badrate = pd.DataFrame(f)
badrate.columns = pd.Series(['cut','badrate'])
badrate = badrate.sort_values('cut')
print(badrate)
badrate.plot('cut','badrate')
```
4）稳定性

PSI
跨时间交叉检验
#### 跨时间交叉检验

就是将样本按照月份切割，一次作为训练集和测试集来训练模型，取进入模型的变量之间的交集，但是要小心共线特征！

解决方法  

- 不需要每次都进入模型，大部分都在即可
- 先去除共线性（这也是为什么集成模型我们也会去除共线性）

PSI计算
```
def var_PSI(dev_data, val_data):
    dev_cnt, val_cnt = sum(dev_data), sum(val_data)
    if dev_cnt * val_cnt == 0:
        return None
    PSI = 0
    for i in range(len(dev_data)):
        dev_ratio = dev_data[i] / dev_cnt
        val_ratio = val_data[i] / val_cnt + 1e-10
        psi = (dev_ratio - val_ratio) * math.log(dev_ratio/val_ratio)
        PSI += psi
    return PSI
```
注意分箱的数量将会影响着变量的PSI值。

PSI并不只可以对模型来求，对变量来求也一样。只需要对跨时间分箱的数据分别求PSI即可。

